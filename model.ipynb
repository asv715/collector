{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onWd_-hfkFjP"
   },
   "source": [
    "## Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6ZwB6QtzjuK9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paXTTHa-kJhw"
   },
   "source": [
    "## Считываем тренировочный датасет и данные сотрудников"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "-wig-ZPwkHMk"
   },
   "outputs": [],
   "source": [
    "df_issues_train = pd.read_csv(\"train_issues.csv\")\n",
    "df_comment_train = pd.read_csv(\"train_comments.csv\")\n",
    "df_emp = pd.read_csv(\"employees.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для удобства приведем названия задач к нижнему регистру\n",
    "df_issues_train['summary'] = df_issues_train.apply(lambda x: str(x['summary']).lower(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируем словарь, в котором ключом является id задачи, а значением - количество комментариев к ней\n",
    "comments_count_train = df_comment_train.groupby(['issue_id']).count().to_dict()['comment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Из данных сотрудников удалим лишние поля\n",
    "df_emp = df_emp.drop([\"active\", \"full_name\", \"passport\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Немного нормализуем назания должностей\n",
    "df_emp['position_norm'] = df_emp.apply(lambda x: str(x['position']).lower().strip(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим бинарные признаки принадлежности \n",
    "\n",
    "df_emp['is_dev'] = df_emp.apply(lambda x: 1 if 'разработчик' in x['position_norm'] else 0, axis=1)\n",
    "df_emp['is_qa'] = df_emp.apply(lambda x: 1 if 'тестировщик' in x['position_norm'] else 0, axis=1)\n",
    "df_emp['is_design'] = df_emp.apply(lambda x: 1 if 'дизайнер' in x['position_norm'] else 0, axis=1)\n",
    "df_emp['is_devops'] = df_emp.apply(lambda x: 1 if 'системный' in x['position_norm'] or 'devops' in x['position_norm'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция преобразования датасета\n",
    "'''\n",
    "\n",
    "def transform_dataset(issues, comments_count):\n",
    "    train = pd.merge(issues, df_emp, left_on=\"assignee_id\", right_on=\"id\", how='inner')\n",
    "    train = train.fillna(0)\n",
    "    train['summary'] = train.apply(lambda x: str(x['summary']).lower(), axis=1)\n",
    "    \n",
    "    train['is_comm'] = train.apply(\n",
    "        lambda x: 1 if 'communicat' in x['summary'] or 'коммуникац' in x['summary'] or 'комуникац' in x['summary'] or 'standup' in x['summary'] or 'all calls' in x['summary'] or 'discussion' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_planning'] = train.apply(\n",
    "        lambda x: 1 if 'planning' in x['summary'] or 'планирование' in x['summary'] or 'оценить' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )    \n",
    "    \n",
    "    train['is_bug'] = train.apply(\n",
    "        lambda x: 1 if 'bug' in x['summary'] or 'incorrect' in x['summary']  or 'fix' in x['summary'] or 'cannot' in x['summary'] or 'исправ' in x['summary'] or 'фикс' in x['summary'] or 'не работает' in x['summary'] or 'проблем' in x['summary'] or 'разобраться' in x['summary'] or 'не вывод' in x['summary'] or 'не показ' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_setup'] = train.apply(\n",
    "        lambda x: 1 if 'jira' in x['summary'] or 'confluence' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_onboarding'] = train.apply(\n",
    "        lambda x: 1 if 'onboard' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_testing_task'] = train.apply(\n",
    "        lambda x: 1 if 'тест' in x['summary'] or 'test' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "      \n",
    "    train['is_dev_task'] = train.apply(\n",
    "        lambda x: 1 if 'develop' in x['summary'] or 'разработ' in x['summary'] or 'изготов' in x['summary'] or 'проектиров' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_administration'] = train.apply(\n",
    "        lambda x: 1 if 'administration' in x['summary'] or 'дежурства админов' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "        \n",
    "    train['is_research_task'] = train.apply(\n",
    "        lambda x: 1 if 'research' in x['summary'] or 'ресерч' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_non_coding'] = train.apply(\n",
    "        lambda x: 1 if 'non-coding' in x['summary'] or 'некод' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    train['is_file_task'] = train.apply(\n",
    "        lambda x: 1 if '.java line' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_frontend'] = train.apply(\n",
    "        lambda x: 1 if 'frontend' in x['summary'] or 'front' in x['summary'] or 'template' in x['summary'] or 'markup' in x['summary'] or 'layout' in x['summary'] or 'верстка' in x['summary'] or ('ui' in x['summary'] and 'test' not in x['summary'] and 'тест' not in x['summary']) or 'styles' in x['summary'] or 'ui-components' in x['summary'] or 'canvas' in x['summary'] or 'svg' in x['summary'] or 'eslint' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_backend'] = train.apply(\n",
    "        lambda x: 1 if 'backend' in x['summary'] or 'integration' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_mobile_task'] = train.apply(\n",
    "        lambda x: 1 if 'android' in x['summary'] or 'mobile' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_design_task'] = train.apply(\n",
    "        lambda x: 1 if 'design' in x['summary'] or 'concept' in x['summary'] or 'ux' in x['summary'] or 'дизайн' in x['summary'] or 'экран' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_seo_task'] = train.apply(\n",
    "        lambda x: 1 if 'seo' in str(x['summary']).lower() else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_api'] = train.apply(\n",
    "        lambda x: 1 if 'api' in x['summary'] or 'endpoint' in x['summary'] or 'эндпоинт' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_refactor'] = train.apply(\n",
    "        lambda x: 1 if 'refactor' in x['summary'] or 'optimize' in x['summary'] or 'rework' in x['summary'] or 'рефактор' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_new_feature'] = train.apply(\n",
    "        lambda x: 1 if 'creat' in x['summary'] or 'add' in x['summary'] or 'implement' in x['summary'] or 'созд' in x['summary'] or 'разработ' in x['summary'] or 'добав' in x['summary'] or 'изготов' in x['summary'] or 'реализ' in x['summary'] or 'собрать' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_update_task'] = train.apply(\n",
    "        lambda x: 1 if 'update' in x['summary'] or 'change' in x['summary'] or 'adjust' in x['summary'] or 'изменить' in x['summary'] or 'поменять' in x['summary'] or 'корректир' in x['summary'] or 'remove' in x['summary'] or 'удалить' in x['summary'] or 'переписать' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    train['is_devops_task'] = train.apply(\n",
    "        lambda x: 1 if 'ci/cd' in x['summary'] or 'pipeline' in x['summary'] or 'branch' in x['summary'] or 'migration' in x['summary'] or 'staging' in x['summary'] or 'logs' in str(x['summary']).lower() or 'uat' in str(x['summary']).lower() or 'deploy' in str(x['summary']).lower() or 'docker' in x['summary'] or 'kuber' in x['summary'] or 'data migration' in x['summary'] or 'поднять' in x['summary'] or 'upgrade' in x['summary'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "   \n",
    "    train['is_self_task'] = train.apply(\n",
    "        lambda x: 1 if x['creator_id']==x['assignee_id'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    train['comments'] = train.apply(\n",
    "        lambda x: comments_count.get(x['id_x'], 0),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Функция формирования файла для отправки\n",
    "'''\n",
    "def save_submit_file(df_test, preds):\n",
    "    df = pd.DataFrame({\n",
    "        'id': list(df_test['id_x']),\n",
    "        'overall_worklogs': list(preds)\n",
    "    })\n",
    "    \n",
    "    df.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLOa56f5zfUg"
   },
   "source": [
    "## Выделим выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = transform_dataset(df_issues_train, comments_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "EdTqs5ixsOkp"
   },
   "outputs": [],
   "source": [
    "stuff = ['id_x', 'id_y', 'overall_worklogs', 'key', 'created', 'summary', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "czsoZexkyyTw"
   },
   "outputs": [],
   "source": [
    "X = df_train.drop(stuff, axis = 1)\n",
    "y = df_train[[\"overall_worklogs\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "E-LfoARf2WGZ"
   },
   "outputs": [],
   "source": [
    "# делим датасет на тренировочную и валидационную выборки\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# логарифмируем таргеты\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_val = np.log(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60NotS9ehbO5"
   },
   "source": [
    "## Построение и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'project_id', 'creator_id', 'position_norm', 'assignee_id', 'hiring_type', \n",
    "    'payment_type', 'english_level', 'salary_calculation_type'\n",
    "]\n",
    "\n",
    "train_pool = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    cat_features=categorical_features\n",
    ")\n",
    "val_pool = Pool(\n",
    "    data=X_val,\n",
    "    label=y_val,\n",
    "    cat_features=categorical_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(\n",
    "    learning_rate=0.0013,\n",
    "    iterations=8000,\n",
    "    depth=8,\n",
    "    random_seed=SEED,\n",
    "    verbose=1000,\n",
    "    l2_leaf_reg=0.02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 1.135167575\n",
      "bestIteration = 4999\n",
      "\n",
      "0:\tloss: 1.1351676\tbest: 1.1351676 (0)\ttotal: 4m 14s\tremaining: 21m 10s\n",
      "\n",
      "bestTest = 1.122338093\n",
      "bestIteration = 5999\n",
      "\n",
      "1:\tloss: 1.1223381\tbest: 1.1223381 (1)\ttotal: 10m 2s\tremaining: 20m 4s\n",
      "\n",
      "bestTest = 1.131813352\n",
      "bestIteration = 4999\n",
      "\n",
      "2:\tloss: 1.1318134\tbest: 1.1223381 (1)\ttotal: 16m 32s\tremaining: 16m 32s\n",
      "\n",
      "bestTest = 1.119316679\n",
      "bestIteration = 5997\n",
      "\n",
      "3:\tloss: 1.1193167\tbest: 1.1193167 (3)\ttotal: 25m 19s\tremaining: 12m 39s\n",
      "\n",
      "bestTest = 1.129307596\n",
      "bestIteration = 4999\n",
      "\n",
      "4:\tloss: 1.1293076\tbest: 1.1193167 (3)\ttotal: 50m 52s\tremaining: 10m 10s\n",
      "\n",
      "bestTest = 1.11697537\n",
      "bestIteration = 5999\n",
      "\n",
      "5:\tloss: 1.1169754\tbest: 1.1169754 (5)\ttotal: 1h 25m 3s\tremaining: 0us\n",
      "Estimating final quality...\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Model was fitted before hyperparameters tuning. You can't change hyperparameters of fitted model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-936-5cc7468ad5ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mgrid_search\u001b[1;34m(self, param_grid, X, y, cv, partition_random_seed, calc_cv_statistics, search_by_train_test_split, refit, shuffle, stratified, train_size, verbose, plot)\u001b[0m\n\u001b[0;32m   3348\u001b[0m             \u001b[0mpartition_random_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartition_random_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalc_cv_statistics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcalc_cv_statistics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3349\u001b[0m             \u001b[0msearch_by_train_test_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msearch_by_train_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3350\u001b[1;33m             \u001b[0mstratified\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3351\u001b[0m         )\n\u001b[0;32m   3352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_tune_hyperparams\u001b[1;34m(self, param_grid, X, y, cv, n_iter, partition_random_seed, calc_cv_statistics, search_by_train_test_split, refit, shuffle, stratified, train_size, verbose, plot)\u001b[0m\n\u001b[0;32m   3254\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3255\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3256\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model was fitted before hyperparameters tuning. You can't change hyperparameters of fitted model.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3257\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcv_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3258\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: Model was fitted before hyperparameters tuning. You can't change hyperparameters of fitted model."
     ]
    }
   ],
   "source": [
    "# Подбор гиперпараметров модели\n",
    "\n",
    "model = CatBoostRegressor(\n",
    "    random_seed=SEED,\n",
    "    verbose=1000\n",
    ")\n",
    "\n",
    "grid = {\n",
    "    'iterations': [8000, 9000, 10000],\n",
    "    'learning_rate': [0.001, 0.0013, 0.0015, 0.0017],\n",
    "    'depth': [8, 9, 10, 11],\n",
    "    'l2_leaf_reg': [0.01, 0.005, 0.2, 0.5, 1]\n",
    "}\n",
    "\n",
    "model.grid_search(grid, train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nan_mode': 'Min',\n",
       " 'eval_metric': 'RMSE',\n",
       " 'combinations_ctr': ['Borders:CtrBorderCount=15:CtrBorderType=Uniform:TargetBorderCount=1:TargetBorderType=MinEntropy:Prior=0/1:Prior=0.5/1:Prior=1/1',\n",
       "  'Counter:CtrBorderCount=15:CtrBorderType=Uniform:Prior=0/1'],\n",
       " 'iterations': 6000,\n",
       " 'sampling_frequency': 'PerTree',\n",
       " 'fold_permutation_block': 0,\n",
       " 'leaf_estimation_method': 'Newton',\n",
       " 'counter_calc_method': 'SkipTest',\n",
       " 'grow_policy': 'SymmetricTree',\n",
       " 'penalties_coefficient': 1,\n",
       " 'boosting_type': 'Plain',\n",
       " 'model_shrink_mode': 'Constant',\n",
       " 'feature_border_type': 'GreedyLogSum',\n",
       " 'ctr_leaf_count_limit': 18446744073709551615,\n",
       " 'bayesian_matrix_reg': 0.10000000149011612,\n",
       " 'one_hot_max_size': 2,\n",
       " 'l2_leaf_reg': 0.20000000298023224,\n",
       " 'random_strength': 1,\n",
       " 'rsm': 1,\n",
       " 'boost_from_average': True,\n",
       " 'max_ctr_complexity': 4,\n",
       " 'model_size_reg': 0.5,\n",
       " 'simple_ctr': ['Borders:CtrBorderCount=15:CtrBorderType=Uniform:TargetBorderCount=1:TargetBorderType=MinEntropy:Prior=0/1:Prior=0.5/1:Prior=1/1',\n",
       "  'Counter:CtrBorderCount=15:CtrBorderType=Uniform:Prior=0/1'],\n",
       " 'subsample': 0.800000011920929,\n",
       " 'use_best_model': True,\n",
       " 'random_seed': 10,\n",
       " 'depth': 8,\n",
       " 'ctr_target_border_count': 1,\n",
       " 'has_time': False,\n",
       " 'store_all_simple_ctr': False,\n",
       " 'border_count': 254,\n",
       " 'classes_count': 0,\n",
       " 'auto_class_weights': 'None',\n",
       " 'sparse_features_conflict_fraction': 0,\n",
       " 'leaf_estimation_backtracking': 'AnyImprovement',\n",
       " 'best_model_min_trees': 1,\n",
       " 'model_shrink_rate': 0,\n",
       " 'min_data_in_leaf': 1,\n",
       " 'loss_function': 'RMSE',\n",
       " 'learning_rate': 0.0013000000035390258,\n",
       " 'score_function': 'Cosine',\n",
       " 'task_type': 'CPU',\n",
       " 'leaf_estimation_iterations': 1,\n",
       " 'bootstrap_type': 'MVS',\n",
       " 'max_leaves': 256,\n",
       " 'permutation_count': 4}"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим параметры лучшей модели\n",
    "\n",
    "model.get_all_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2278355\ttest: 1.2635757\tbest: 1.2635757 (0)\ttotal: 55.2ms\tremaining: 7m 21s\n",
      "1000:\tlearn: 1.1253212\ttest: 1.1838093\tbest: 1.1838093 (1000)\ttotal: 1m\tremaining: 7m 3s\n",
      "2000:\tlearn: 1.0896428\ttest: 1.1606465\tbest: 1.1606465 (2000)\ttotal: 2m 19s\tremaining: 6m 58s\n",
      "3000:\tlearn: 1.0691922\ttest: 1.1502616\tbest: 1.1502616 (3000)\ttotal: 3m 40s\tremaining: 6m 6s\n",
      "4000:\tlearn: 1.0544254\ttest: 1.1443863\tbest: 1.1443863 (4000)\ttotal: 4m 52s\tremaining: 4m 52s\n",
      "5000:\tlearn: 1.0422301\ttest: 1.1398428\tbest: 1.1398427 (4999)\ttotal: 5m 59s\tremaining: 3m 35s\n",
      "6000:\tlearn: 1.0308597\ttest: 1.1362177\tbest: 1.1362177 (6000)\ttotal: 7m 19s\tremaining: 2m 26s\n",
      "7000:\tlearn: 1.0191638\ttest: 1.1327091\tbest: 1.1327091 (7000)\ttotal: 8m 30s\tremaining: 1m 12s\n",
      "7999:\tlearn: 1.0065614\ttest: 1.1293039\tbest: 1.1293039 (7999)\ttotal: 9m 39s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.12930387\n",
      "bestIteration = 7999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x243797730c8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отдельно вынесем процесс обучения модели с подобранными параметрами для воспроизведения и проверки результата\n",
    "model = CatBoostRegressor(\n",
    "    learning_rate=0.0013,\n",
    "    iterations=8000,\n",
    "    depth=8,\n",
    "    random_seed=SEED,\n",
    "    verbose=1000,\n",
    "    l2_leaf_reg=0.02\n",
    ")\n",
    "\n",
    "model.fit(train_pool, use_best_model=True, eval_set=val_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим предсказания для тренировочного и валидационного датасета\n",
    "\n",
    "pred_train = model.predict(X_train)\n",
    "pred_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2853365554560179, 0.19931869626977516)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оценим метрику R2\n",
    "\n",
    "r2_score(y_train, pred_train), r2_score(y_val, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим на вклад каждого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_id -> 7.845958223011912\n",
      "assignee_id -> 14.097102156277604\n",
      "creator_id -> 14.386261994301796\n",
      "hiring_type -> 3.4951658569934114\n",
      "payment_type -> 6.917930072715343\n",
      "salary_calculation_type -> 2.234793989846647\n",
      "english_level -> 4.125239364145091\n",
      "is_nda_signed -> 0.3927404594841476\n",
      "is_labor_contract_signed -> 0.3560178116828472\n",
      "is_added_to_internal_chats -> 0.4382536182604846\n",
      "is_added_one_to_one -> 0.16571780636075872\n",
      "position_norm -> 4.792906988262446\n",
      "is_dev -> 0.48893835219659243\n",
      "is_qa -> 0.00046879383002248494\n",
      "is_design -> 0.028489279288606013\n",
      "is_devops -> 0.09995255906075394\n",
      "is_comm -> 5.89783402435394\n",
      "is_planning -> 1.1480119240819688\n",
      "is_bug -> 1.5555547507016032\n",
      "is_setup -> 0.2513450378514521\n",
      "is_onboarding -> 0.24200080076692718\n",
      "is_testing_task -> 1.2806867941536386\n",
      "is_dev_task -> 0.5216808185383759\n",
      "is_administration -> 0.2128352708829292\n",
      "is_research_task -> 0.5932977652793798\n",
      "is_non_coding -> 0.052199909897528755\n",
      "is_file_task -> 0.022265753302683277\n",
      "is_frontend -> 3.4522056765462317\n",
      "is_backend -> 0.04928155791585462\n",
      "is_mobile_task -> 0.05544195494259863\n",
      "is_design_task -> 1.0958780790704081\n",
      "is_seo_task -> 0.0013707845024963415\n",
      "is_api -> 0.7196149800891097\n",
      "is_refactor -> 1.7761179922599213\n",
      "is_new_feature -> 1.0535913155690317\n",
      "is_update_task -> 1.1803159866368538\n",
      "is_devops_task -> 1.149907676074521\n",
      "is_self_task -> 3.194644390251819\n",
      "comments -> 14.627979430611518\n"
     ]
    }
   ],
   "source": [
    "columns = list(X_train.columns)\n",
    "for index, value in enumerate(model.get_feature_importance()):\n",
    "    print(columns[index], value, sep=' -> ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Y60HHS5jKeN"
   },
   "source": [
    "## Считываем и преобразуем тестовый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_issues.csv')\n",
    "df_comment_test = pd.read_csv('test_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_count_test = df_comment_test.groupby(['issue_id']).count().to_dict()['comment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = transform_dataset(df_test, comments_count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = ['id_x', 'id_y', 'key', 'created', 'summary', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(stuff, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получаем предсказания и готовим файл для отправки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем предсказания: вычисляем экспоненту, округляем до минут и часов \n",
    "modified_preds = list(map(lambda x: np.ceil(x / 60) * 60, np.round(np.exp(pred_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submit_file(df_test, modified_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
